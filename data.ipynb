{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dfdb2a72-c134-417e-b364-c7aa881c53c9",
      "metadata": {
        "id": "dfdb2a72-c134-417e-b364-c7aa881c53c9",
        "outputId": "7d0b4ad6-7b4e-4da6-dbba-4b56bf070096"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting nltk\n",
            "  Using cached nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting click (from nltk)\n",
            "  Using cached click-8.2.1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting joblib (from nltk)\n",
            "  Using cached joblib-1.5.1-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting regex>=2021.8.3 (from nltk)\n",
            "  Using cached regex-2024.11.6-cp313-cp313-win_amd64.whl.metadata (41 kB)\n",
            "Collecting tqdm (from nltk)\n",
            "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "Requirement already satisfied: colorama in c:\\users\\vivek\\onedrive\\desktop\\vivak\\data-analatics\\.venv\\lib\\site-packages (from click->nltk) (0.4.6)\n",
            "Using cached nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
            "Using cached regex-2024.11.6-cp313-cp313-win_amd64.whl (273 kB)\n",
            "Using cached click-8.2.1-py3-none-any.whl (102 kB)\n",
            "Using cached joblib-1.5.1-py3-none-any.whl (307 kB)\n",
            "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "Installing collected packages: tqdm, regex, joblib, click, nltk\n",
            "\n",
            "   ---------------------------------------- 0/5 [tqdm]\n",
            "   ---------------------------------------- 0/5 [tqdm]\n",
            "   -------- ------------------------------- 1/5 [regex]\n",
            "   ---------------- ----------------------- 2/5 [joblib]\n",
            "   ---------------- ----------------------- 2/5 [joblib]\n",
            "   ---------------- ----------------------- 2/5 [joblib]\n",
            "   ---------------- ----------------------- 2/5 [joblib]\n",
            "   ---------------- ----------------------- 2/5 [joblib]\n",
            "   ---------------- ----------------------- 2/5 [joblib]\n",
            "   ------------------------ --------------- 3/5 [click]\n",
            "   ------------------------ --------------- 3/5 [click]\n",
            "   -------------------------------- ------- 4/5 [nltk]\n",
            "   -------------------------------- ------- 4/5 [nltk]\n",
            "   -------------------------------- ------- 4/5 [nltk]\n",
            "   -------------------------------- ------- 4/5 [nltk]\n",
            "   -------------------------------- ------- 4/5 [nltk]\n",
            "   -------------------------------- ------- 4/5 [nltk]\n",
            "   -------------------------------- ------- 4/5 [nltk]\n",
            "   -------------------------------- ------- 4/5 [nltk]\n",
            "   -------------------------------- ------- 4/5 [nltk]\n",
            "   -------------------------------- ------- 4/5 [nltk]\n",
            "   -------------------------------- ------- 4/5 [nltk]\n",
            "   -------------------------------- ------- 4/5 [nltk]\n",
            "   -------------------------------- ------- 4/5 [nltk]\n",
            "   -------------------------------- ------- 4/5 [nltk]\n",
            "   -------------------------------- ------- 4/5 [nltk]\n",
            "   -------------------------------- ------- 4/5 [nltk]\n",
            "   -------------------------------- ------- 4/5 [nltk]\n",
            "   -------------------------------- ------- 4/5 [nltk]\n",
            "   -------------------------------- ------- 4/5 [nltk]\n",
            "   -------------------------------- ------- 4/5 [nltk]\n",
            "   -------------------------------- ------- 4/5 [nltk]\n",
            "   -------------------------------- ------- 4/5 [nltk]\n",
            "   -------------------------------- ------- 4/5 [nltk]\n",
            "   -------------------------------- ------- 4/5 [nltk]\n",
            "   -------------------------------- ------- 4/5 [nltk]\n",
            "   -------------------------------- ------- 4/5 [nltk]\n",
            "   -------------------------------- ------- 4/5 [nltk]\n",
            "   -------------------------------- ------- 4/5 [nltk]\n",
            "   ---------------------------------------- 5/5 [nltk]\n",
            "\n",
            "Successfully installed click-8.2.1 joblib-1.5.1 nltk-3.9.1 regex-2024.11.6 tqdm-4.67.1\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22d997be-1c4e-4136-946f-3b47c3b0d057",
      "metadata": {
        "id": "22d997be-1c4e-4136-946f-3b47c3b0d057",
        "outputId": "3716bcec-52b6-46d2-f74b-559a3c7c23be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84be780a-f2da-482e-ac38-01fe180814bd",
      "metadata": {
        "id": "84be780a-f2da-482e-ac38-01fe180814bd",
        "outputId": "7cd3a4be-287a-4ead-81bb-9152faf7250f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Barack Obama went as a prime minister of USA in the year of 2015 . PM MODI is the prime minister of INDIA.\n"
          ]
        }
      ],
      "source": [
        "input = \"Barack Obama went as a prime minister of USA in the year of 2015 . PM MODI is the prime minister of INDIA.\"\n",
        "print(input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0bab8cae-ded2-4903-bec4-f2dfde2ca61a",
      "metadata": {
        "id": "0bab8cae-ded2-4903-bec4-f2dfde2ca61a",
        "outputId": "5fc68b71-79bb-4e63-d218-cc373b705051"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LOWERCSE =  barack obama went as a prime minister of usa in the year of 2015 . pm modi is the prime minister of india.\n",
            "REGULAR EXP1 =  barack obama went as a prime minister of usa in the year of 2025 . pm modi is the prime minister of india.\n",
            "REGULAR EXP2 =  **r*** o**** w*nt *s * pr*** **n*st*r o* us* *n t** y**r o* 2015 . p* *o** *s t** pr*** **n*st*r o* *n***.\n",
            "REGULAR EXP3 =  barack obama went as a prime minister of usa in the year of ---- . pm modi is the prime minister of india.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<>:12: SyntaxWarning: invalid escape sequence '\\d'\n",
            "<>:12: SyntaxWarning: invalid escape sequence '\\d'\n",
            "C:\\Users\\vivek\\AppData\\Local\\Temp\\ipykernel_21768\\1413414172.py:12: SyntaxWarning: invalid escape sequence '\\d'\n",
            "  lowercase_re = re.sub('\\d', '-', lowercase)\n"
          ]
        }
      ],
      "source": [
        "#(1)lowercase\n",
        "lowercase = input.lower()\n",
        "print(\"LOWERCSE = \", lowercase)\n",
        "\n",
        "#re\n",
        "#pip install re\n",
        "import re\n",
        "lowercase_re = re.sub('2015', '2025', lowercase)\n",
        "print(\"REGULAR EXP1 = \", lowercase_re)\n",
        "lowercase_re = re.sub('[a-m]', '*', lowercase)\n",
        "print(\"REGULAR EXP2 = \", lowercase_re)\n",
        "lowercase_re = re.sub('\\d', '-', lowercase)\n",
        "print(\"REGULAR EXP3 = \", lowercase_re)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34bb092b-1d69-4aa9-abd4-131d9d934c36",
      "metadata": {
        "id": "34bb092b-1d69-4aa9-abd4-131d9d934c36",
        "outputId": "9f925149-ba41-44bc-f89a-83c215786d7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WORD TOKENS =  ['Barack', 'Obama', 'went', 'as', 'a', 'prime', 'minister', 'of', 'USA', 'in', 'the', 'year', 'of', '2015', '.', 'PM', 'MODI', 'is', 'the', 'prime', 'minister', 'of', 'INDIA', '.']\n",
            "24\n",
            "SENT TOKENS =  ['Barack Obama went as a prime minister of USA in the year of 2015 .', 'PM MODI is the prime minister of INDIA.']\n",
            "2\n"
          ]
        }
      ],
      "source": [
        "#(2)Tokenization\n",
        "import nltk\n",
        "from nltk import word_tokenize, sent_tokenize\n",
        "\n",
        "word_tokens = word_tokenize(input)\n",
        "print(\"WORD TOKENS = \", word_tokens)\n",
        "print(len(word_tokens))\n",
        "sent_tokens = sent_tokenize(input)\n",
        "print(\"SENT TOKENS = \", sent_tokens)\n",
        "print(len(sent_tokens))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a15a5f9e-6468-4df9-b139-ae37b404df67",
      "metadata": {
        "id": "a15a5f9e-6468-4df9-b139-ae37b404df67",
        "outputId": "6bb984a2-3f97-4607-c62e-41076d2cec74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Barack Obama went prime minister USA year 2015 . PM MODI prime minister INDIA .\n"
          ]
        }
      ],
      "source": [
        "#(3)stopwords Removal\n",
        "from nltk.corpus import stopwords\n",
        "#print(stopwords.fileids())\n",
        "stopwords = set(stopwords.words('english'))\n",
        "#print(\"\\n\", stopwords)\n",
        "\n",
        "tokens_stopwords = []\n",
        "for token in word_tokens:\n",
        "    if token not in stopwords:\n",
        "        tokens_stopwords.append(token)\n",
        "print(' '.join(tokens_stopwords))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2897d3f7-fb88-4ac4-a37e-68005f9f7bac",
      "metadata": {
        "id": "2897d3f7-fb88-4ac4-a37e-68005f9f7bac",
        "outputId": "eea73fbb-5ebc-4852-b2b0-9aac478e6010"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['barack', 'obama', 'went', 'prime', 'minist', 'usa', 'year', '2015', '.', 'pm', 'modi', 'prime', 'minist', 'india', '.']\n"
          ]
        }
      ],
      "source": [
        "#Stemmer\n",
        "stemming = []\n",
        "from nltk import PorterStemmer\n",
        "for word in tokens_stopwords:\n",
        "    stemming.append(PorterStemmer().stem(word))\n",
        "print(stemming)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f849b2a4-4a9a-4f12-9859-fe441b343af1",
      "metadata": {
        "id": "f849b2a4-4a9a-4f12-9859-fe441b343af1",
        "outputId": "bebf386b-d78b-4151-f591-5f14dc82c121"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Barack', 'Obama', 'went', 'prime', 'minister', 'USA', 'year', '2015', '.', 'PM', 'MODI', 'prime', 'minister', 'INDIA', '.']\n"
          ]
        }
      ],
      "source": [
        "#Lemmatizer\n",
        "from nltk import WordNetLemmatizer\n",
        "lma = []\n",
        "for word in tokens_stopwords:\n",
        "    lma.append(WordNetLemmatizer().lemmatize(word))\n",
        "print(lma)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c67a677-3a79-4167-982e-6edb592803bf",
      "metadata": {
        "id": "5c67a677-3a79-4167-982e-6edb592803bf",
        "outputId": "9fe88f5e-ffb5-465d-b8c3-289c40a5f7ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('Barack', 'NNP'), ('Obama', 'NNP'), ('went', 'VBD'), ('as', 'IN'), ('a', 'DT'), ('prime', 'JJ'), ('minister', 'NN'), ('of', 'IN'), ('USA', 'NNP'), ('in', 'IN'), ('the', 'DT'), ('year', 'NN'), ('of', 'IN'), ('2015', 'CD'), ('.', '.'), ('PM', 'NNP'), ('MODI', 'NNP'), ('is', 'VBZ'), ('the', 'DT'), ('prime', 'JJ'), ('minister', 'NN'), ('of', 'IN'), ('INDIA', 'NNP'), ('.', '.')]\n"
          ]
        }
      ],
      "source": [
        "#POS Tags\n",
        "from nltk import pos_tag\n",
        "print(pos_tag(word_tokens))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06f44a50-86ca-4760-a2fe-162ff8aa59b5",
      "metadata": {
        "id": "06f44a50-86ca-4760-a2fe-162ff8aa59b5",
        "outputId": "2326b56e-520d-4e8d-9357-8130fbd28df0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', ...]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from nltk.corpus import brown\n",
        "brown.words()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83c5bde8",
      "metadata": {
        "id": "83c5bde8",
        "outputId": "cf8bd26d-5714-4ffd-cbd8-818c2832cc7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "*** Introductory Examples for the NLTK Book ***\n",
            "Loading text1, ..., text9 and sent1, ..., sent9\n",
            "Type the name of the text or sentence to view it.\n",
            "Type: 'texts()' or 'sents()' to list the materials.\n",
            "text1: Moby Dick by Herman Melville 1851\n",
            "text2: Sense and Sensibility by Jane Austen 1811\n",
            "text3: The Book of Genesis\n",
            "text4: Inaugural Address Corpus\n",
            "text5: Chat Corpus\n",
            "text6: Monty Python and the Holy Grail\n",
            "text7: Wall Street Journal\n",
            "text8: Personals Corpus\n",
            "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
          ]
        }
      ],
      "source": [
        "from nltk.book import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd6512c6",
      "metadata": {
        "id": "bd6512c6",
        "outputId": "6869450f-bcea-4982-9882-1847821adf18"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Text: Moby Dick by Herman Melville 1851>"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56f130fd",
      "metadata": {
        "id": "56f130fd",
        "outputId": "a0dff3e6-4c8c-4368-db99-7fd4847476fa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Text: Sense and Sensibility by Jane Austen 1811>"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe51c4eb",
      "metadata": {
        "id": "fe51c4eb",
        "outputId": "699e02db-c98d-497d-969e-680d7520590c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Displaying 11 of 11 matches:\n",
            "ong the former , one was of a most monstrous size . ... This came towards us , \n",
            "ON OF THE PSALMS . \" Touching that monstrous bulk of the whale or ork we have r\n",
            "ll over with a heathenish array of monstrous clubs and spears . Some were thick\n",
            "d as you gazed , and wondered what monstrous cannibal and savage could ever hav\n",
            "that has survived the flood ; most monstrous and most mountainous ! That Himmal\n",
            "they might scout at Moby Dick as a monstrous fable , or still worse and more de\n",
            "th of Radney .'\" CHAPTER 55 Of the Monstrous Pictures of Whales . I shall ere l\n",
            "ing Scenes . In connexion with the monstrous pictures of whales , I am strongly\n",
            "ere to enter upon those still more monstrous stories of them which are to be fo\n",
            "ght have been rummaged out of this monstrous cabinet there is no telling . But \n",
            "of Whale - Bones ; for Whales of a monstrous size are oftentimes cast up dead u\n"
          ]
        }
      ],
      "source": [
        "text1.concordance(\"monstrous\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95092cac",
      "metadata": {
        "id": "95092cac",
        "outputId": "6692a792-42a9-4ccb-f777-b9802548464f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "true contemptible christian abundant few part mean careful puzzled\n",
            "mystifying passing curious loving wise doleful gamesome singular\n",
            "delightfully perilous fearless\n"
          ]
        }
      ],
      "source": [
        "text1.similar(\"monstrous\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7662dba5",
      "metadata": {
        "id": "7662dba5",
        "outputId": "f7050cbb-7a11-465a-ace9-1baac6b6e104"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "very so exceedingly heartily a as good great extremely remarkably\n",
            "sweet vast amazingly\n"
          ]
        }
      ],
      "source": [
        "text2.similar(\"monstrous\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4bee1a03",
      "metadata": {
        "id": "4bee1a03",
        "outputId": "fdb26568-1843-4bf4-eadc-03535fc58757"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting tensorflow\n",
            "  Obtaining dependency information for tensorflow from https://files.pythonhosted.org/packages/3c/e3/e868f1d5951047f950d2ba1e04a765a3328a51f06996b67976d6102f8227/tensorflow-2.19.0-cp311-cp311-win_amd64.whl.metadata\n",
            "  Using cached tensorflow-2.19.0-cp311-cp311-win_amd64.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\vivek\\anac\\lib\\site-packages (from tensorflow) (2.3.1)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\vivek\\anac\\lib\\site-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\vivek\\anac\\lib\\site-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\vivek\\anac\\lib\\site-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\vivek\\anac\\lib\\site-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\vivek\\anac\\lib\\site-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\vivek\\anac\\lib\\site-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in c:\\users\\vivek\\anac\\lib\\site-packages (from tensorflow) (23.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\vivek\\anac\\lib\\site-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\vivek\\anac\\lib\\site-packages (from tensorflow) (2.31.0)\n",
            "Requirement already satisfied: setuptools in c:\\users\\vivek\\anac\\lib\\site-packages (from tensorflow) (68.0.0)\n",
            "Requirement already satisfied: six>=1.12.0 in c:\\users\\vivek\\anac\\lib\\site-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\vivek\\anac\\lib\\site-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\vivek\\anac\\lib\\site-packages (from tensorflow) (4.7.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\vivek\\anac\\lib\\site-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\vivek\\anac\\lib\\site-packages (from tensorflow) (1.73.1)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in c:\\users\\vivek\\anac\\lib\\site-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in c:\\users\\vivek\\anac\\lib\\site-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in c:\\users\\vivek\\anac\\lib\\site-packages (from tensorflow) (2.1.3)\n",
            "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\vivek\\anac\\lib\\site-packages (from tensorflow) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in c:\\users\\vivek\\anac\\lib\\site-packages (from tensorflow) (0.5.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\vivek\\anac\\lib\\site-packages (from tensorflow) (0.31.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\vivek\\anac\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\n",
            "Requirement already satisfied: rich in c:\\users\\vivek\\anac\\lib\\site-packages (from keras>=3.5.0->tensorflow) (14.0.0)\n",
            "Requirement already satisfied: namex in c:\\users\\vivek\\anac\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in c:\\users\\vivek\\anac\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\vivek\\anac\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\vivek\\anac\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\vivek\\anac\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\vivek\\anac\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2023.7.22)\n",
            "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\vivek\\anac\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\vivek\\anac\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\vivek\\anac\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\vivek\\anac\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (2.1.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\vivek\\anac\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.2.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\vivek\\anac\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.15.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in c:\\users\\vivek\\anac\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Using cached tensorflow-2.19.0-cp311-cp311-win_amd64.whl (375.9 MB)\n",
            "Installing collected packages: tensorflow\n",
            "Successfully installed tensorflow-2.19.0\n"
          ]
        }
      ],
      "source": [
        "! pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74d09b5c",
        "outputId": "0482959a-bfe4-49eb-ebe8-7e3b00920cf0"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "id": "74d09b5c",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4e394620",
        "outputId": "f824786c-fa7f-45a1-8b30-dc83765f23fc"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')"
      ],
      "id": "4e394620",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TF-IDF\n",
        "from nltk import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "#pip install scikit-learn\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "stopwords = set(stopwords.words('english'))\n",
        "ps = PorterStemmer()\n",
        "vector = TfidfVectorizer()\n",
        "\n",
        "documents= [ \"apple boy cat\", \"apple cat dog\", \"dog egg fan\" ]\n",
        "\n",
        "preprocessed = []\n",
        "for doc in documents:\n",
        "    tokenization = word_tokenize(doc)\n",
        "    stop = [ps.stem(word) for word in tokenization if word not in stopwords]\n",
        "    preprocessed.append(\" \".join(stop))\n",
        "print(preprocessed)\n",
        "word_score = vector.fit_transform(preprocessed)\n",
        "print(word_score)"
      ],
      "metadata": {
        "id": "HV8jUH56SSHW",
        "outputId": "2f596175-ab98-4cdf-ed99-64a608c89433",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "HV8jUH56SSHW",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['appl boy cat', 'appl cat dog', 'dog egg fan']\n",
            "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
            "\twith 9 stored elements and shape (3, 6)>\n",
            "  Coords\tValues\n",
            "  (0, 0)\t0.5178561161676974\n",
            "  (0, 1)\t0.680918560398684\n",
            "  (0, 2)\t0.5178561161676974\n",
            "  (1, 0)\t0.5773502691896257\n",
            "  (1, 2)\t0.5773502691896257\n",
            "  (1, 3)\t0.5773502691896257\n",
            "  (2, 3)\t0.4736296010332684\n",
            "  (2, 4)\t0.6227660078332259\n",
            "  (2, 5)\t0.6227660078332259\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}